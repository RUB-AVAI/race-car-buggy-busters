The goal of the project is the development of an autonomous race car capable of completing at least one lap on an indoor track in a fast yet safe manner.
The vehicle is positioned in the driving direction at the start. The race environment follows the F1TENTH cone system, where blue cones mark the left boundary, yellow cones mark the right boundary, and the start zone is identified by orange cones on both sides.
The track is a closed-loop circuit without any branches, and its layout changes between races. The vehicle operates without other cars on the track, with a maximum speed of approximately 15 km/h. 
A perception round precedes the timed lap. The system utilizes ROS2 Humble for software integration and runs on an NVIDIA Jetson NX 16GB. The vehicle is equipped with a 3D + mono depth camera (Intel RealSense Depth Camera D435i) and a high-resolution 2D LiDAR (Hokuyo UST-10), and features a four-wheel-drive system with Ackermann steering for navigation. \textbf{TODO: Add our assumptions/expectations towards the project.}\\
\newline
Below are our functional and quality requirements listed for this project:
\textbf{TODO: Turn item list into table and add Must/Should/Could Have as additional column}
\subsection{Functional Requirements}

\begin{itemize}
    \item \textbf{General Perception}: The vehicle shall capture real-time 3D depth data using the Hokuyo UST-10 LiDAR and high-resolution visual data using the Intel RealSense Depth Camera D435i to perceive the environment.
    \item \textbf{Object Detection \& Classification}: The system shall detect and classify blue cones marking the left track boundary and yellow cones marking the right track boundary in real-time.
    \item \textbf{Cone Detection}: When on track, the vehicle shall detect cones marking the track boundaries in real-time using the camera and LiDAR sensors.
    \item \textbf{Sensor Fusion}: When collecting data, the perception system shall integrate LiDAR and camera data using a sensor fusion algorithm to improve cone detection accuracy.
    \item \textbf{Distance Estimation}: While driving, the vehicle shall estimate the distance to the track boundaries continuously.
    \item \textbf{Point Cloud}: The vehicle shall collect 3D LiDAR point cloud data to detect and map its surroundings in real-time.
    \item \textbf{Visual Data}: The camera system shall provide input for visual odometry and SLAM, ensuring accurate self-localization.
    \item \textbf{Self-Localization}: The vehicle shall localize its position relative to track boundaries using fused data from LiDAR, camera, and odometry.
    \item \textbf{Real-Time Map}: The vehicle shall generate a real-time map of the environment using LiDAR and visual sensors, aiding in cone detection and path planning.
    \item \textbf{Environments}: The system shall be able to handle both static and dynamic environments, where the track layout may change.
    \item \textbf{Optimal Trajectory}: When planning the path, the vehicle shall generate an optimal trajectory within track boundaries using the detected cone positions and real-time sensor data, maintaining the desired speed.
    \item \textbf{Path Planning}: The vehicle shall implement a planning algorithm that works in real time, adjusting paths as the environment changes.
    \item \textbf{Path Updates}: The path planner shall compute new trajectories dynamically to handle sudden track changes.
    \item \textbf{Acceleration \& Deceleration}: The vehicle shall decide when to accelerate, decelerate, or stop, depending on the environment.
    \item \textbf{Driving Modes}: The vehicle shall be able to switch between different driving modes (e.g., cruising, emergency stop) based on the context.
    \item \textbf{Speed Maintenance}: The vehicle shall maintain the fastest appropriate speed for the calculated paths on the track layout, not exceeding 15 km/h.
    \item \textbf{Acceleration Adaptation}: The system shall adapt acceleration to keep the vehicle within speed limits, adjusting for factors like road slope, friction, and other dynamic conditions.
    \item \textbf{Sharp Turns}: While approaching sharp turns, the vehicle shall adjust its speed to ensure safe cornering without exceeding the track boundaries.
    \item \textbf{Smooth Acceleration}: When accelerating, the vehicle must limit its acceleration to avoid jerky movements using a soft acceleration curve, ensuring smooth control.
    \item \textbf{Braking}: The vehicle shall be able to brake in real-time to slow down or stop based on planned behavior or unexpected events.
    \item \textbf{Controlled Emergency Braking}: When braking, the vehicle shall decelerate within a controlled distance to avoid overshooting turns or track boundaries.
    \item \textbf{Steering Angle}: When controlling the steering, the vehicle shall calculate the optimal steering angle based on the track curvature and current speed.
    \item \textbf{Steering}: The vehicle shall control the Ackerman steering system to follow the planned trajectory accurately.
    \item \textbf{Smooth Steering}: The control system shall ensure stable and smooth steering, especially at high speeds.
    \item \textbf{External Signals}: The system shall respond appropriately to external signals and traffic rules defined for the track.
    \item \textbf{Failsafe Mode}: When a critical system failure is detected, the vehicle shall engage the emergency braking system to bring the vehicle to a stop.
    \item \textbf{System Health}: When system health is checked, the vehicle shall monitor the status of all sensors, compute hardware, and actuators in real-time to ensure continuous operation.
    \item \textbf{Odometry}: The vehicle shall collect odometry data to track its speed, orientation, and position over time.
    \item \textbf{Health Checks}: The system shall implement watchdog timers and health-check nodes to detect failures or malfunctions in any part of the system.
    \item \textbf{Vehicle Tracking}: The system shall provide continuous and real-time feedback on the vehicle's movement and position to maintain trajectory tracking.
    \item \textbf{Internal Communication}: All sensors, actuators, and the onboard compute hardware shall communicate via ROS2 Humble, using DDS for real-time message passing.
    \item \textbf{Manual Override Mode}: The system should be able to transition to a manual override mode in case of critical failures, allowing the race team to take control if necessary.
    \item \textbf{Partial System Failures}: The system shall include multiple levels of safety checks, and emergency overrides shall be functional even in the event of partial system failures.
    \item \textbf{Testing}: The vehicle shall be tested in both simulation and real-world environments to validate its perception, planning, and control systems.
\end{itemize}

\subsection{Quality Requirements}

\begin{itemize}
    \item \textbf{Sensor Processing Latency}: The system shall process sensor data in real-time with latency under 50 ms to ensure timely decision-making and control.
    \item \textbf{Control Loop Frequency}: The vehicle shall maintain a control loop update frequency of 20-30 Hz to ensure smooth and responsive driving at max. 15 km/h.
    \item \textbf{Localization Accuracy}: The localization system shall maintain position \(\pm 10\) cm to ensure the vehicle stays within the track boundaries.
    \item \textbf{Perception Radius}: The perception system shall detect cones at least 10 meters ahead to provide sufficient time for path adjustments.
    \item \textbf{Emergency Braking Distance}: The vehicle shall decelerate within 2-3 meters when the emergency braking system is engaged to ensure safe stopping.
    \item \textbf{Emergency Stop}: The vehicle shall engage the emergency braking system within 100 ms of detecting critical system failures to avoid accidents.
    \item \textbf{Detection Rate}: The perception system shall maintain a continuous detection rate of at least 95\% for cones to prevent boundary violations.
\end{itemize}
